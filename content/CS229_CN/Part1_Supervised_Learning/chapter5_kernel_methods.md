---
title: 第 5 章 核方法
---
| [[chapter4_generative_learning_algorithms\|上一章]] | [[CS229_CN/index\|目录]] | 下一章 |
| :----------------------------------------------: | :--------------------: | :-: |

## 5.1 特征映射

回顾在线性回归的讨论中，考虑了根据房屋的居住面积 (记为 $x$ ) 预测房屋价格 (记为 $y$ ) 的问题，并将 $x$ 的线性函数拟合到训练数据。如果价格 $y$ 可以更准确地表示为 $x$ 的 *非线性 (non-linear)* 函数呢？在这种情况下，需要一个比线性模型更具表现力的模型族。

## 5.2 特征的最小均方

lorem

## 5.3 使用核技巧的最小均方

lorem

## 5.4 核的性质

在上一小节中，从一个显式定义的特征映射 $\phi$ 开始，导出了核函数 $K(x, z) \triangleq \langle \phi(x), \phi(z) \rangle$. 然后，看到核函数是如此本质，只要核函数被定义，整个训练算法就可以完全用核方法的语言编写，而无需引用特征映射 $\phi$，因此对于测试示例 $x$ 的预测 (方程 \eqref{eq:kernel_essence}) 也是如此。

因此，可以尝试定义其他核函数 $K(\cdot, \cdot)$ 并运行算法 \eqref{eq:kernel_algo}。请注意，算法 \eqref{eq:kernel_algo} 不需要显式访问特征映射 $\phi$, 因此只需要确保特征映射 $\phi$ 的存在，但不一定需要能够显式写下 $\phi$.

哪些类型的函数 $K(\cdot, \cdot)$ 可以对应于某个特征映射 $\phi$? 换句话说，能否判断出来是否存在某个特征映射 $\phi$ 使得对于所有 $x, z$ 都有 $K(x, z) = \phi(x)^T \phi(z)$?

如果可以通过给出有效核函数的精确表征来回答这个问题，那么就可以完全改变选择核函数  的接口，而不是选择特征映射 $\phi$ 的接口。具体来说，可以选取一个函数 ，验证它满足该表征 (从而存在一个与 $K$ 对应的特征映射 $\phi$ )，然后就可以运行更新规则 \eqref{eq:kernel_algo}。这里的好处是，不需要能够计算或解析地写下 $\phi$, 只需要知道它的存在性。在本小节的末尾，将通过几个具体的核示例回答这个问题。

假设 $x, z \in \mathbb{R}^d$，首先考虑函数 $K(\cdot, \cdot)$ 定义为：

### 核作为相似性度量

lorem

### 有效核的必要条件

lorem

### 有效核的充分条件

lorem

### 核方法的应用

我们已经看到了核方法在线性回归中的应用。在下一部分，将介绍支持向量机，核方法可以直接应用于其中。这里不再赘述。实际上，核方法的思想比线性回归和 SVM 具有更广泛的适用性。具体来说，如果有一个学习算法，可以完全用输入属性向量之间的内积 $\langle x, z \rangle$ 来表达，那么通过将其替换为核 $K(x, z)$ (其中 $K$ 是一个核)，就可以“神奇地”让算法在对应于 $K$ 的高维特征空间中高效工作。例如，这个核技巧可以应用于感知机，推导出核感知机算法。本课程后面将看到的许多算法也将适用于这种方法，这种方法被称为“核技巧”。

| [[chapter4_generative_learning_algorithms\|上一章]] | [[CS229_CN/index\|目录]] | 下一章 |
| :----------------------------------------------: | :--------------------: | :-: |