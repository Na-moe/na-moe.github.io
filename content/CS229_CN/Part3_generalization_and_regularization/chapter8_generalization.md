---
title: 第 8 章 泛化
---

| [[chapter7_deep_learning\|上一章]] | [[CS229_CN/index#目录\|目录]] | [[chapter7_deep_learning\|下一章]] |
| :-----------------------------: | :-----------------------: | :-----------------------------: |

本章将讨论理解和分析机器学习模型泛化能力的工具，即这些模型在未见过的测试样本上的表现。回想一下，对于监督学习问题，给定训练数据集 $\{(x^{(i)}, y^{(i)})\}_{i=1}^n$, 通常通过最小化损失/成本函数 $J(\theta)$ 来学习模型 $h_\theta$, 这鼓励 $h_\theta$ 拟合数据。例如，当损失函数是最小二乘损失 (也称为均方误差) 时，有 $J(\theta) = \frac{1}{n} \sum_{i=1}^n \left(y^{(i)} - h_\theta(x^{(i)})\right)^2$, 这个用于训练的损失函数通常被称为 **训练 (training)** 损失/误差/代价。

然而，最小化训练损失 **并非** 最终目标，它只是实现学习预测模型这一目标的途径。模型最重要的评估指标是在未见过的测试样本上的损失，通常被称为测试误差。形式上，从所谓的测试分布 $\mathcal{D}$ 中抽取一个测试样本 $(x, y)$，并衡量模型在其上的误差，例如均方误差 $(h_\theta(x) - y)^2$。测试样本随机性下的期望损失/误差称为测试损失/误差。[^1]

$$
L(\theta) = \mathbb{E}_{(x,y) \sim \mathcal{D}}[(y - h_\theta(x))^2] \tag{8.1}
$$

请注意，误差的测量涉及计算期望，在实践中，可以通过对许多抽取的测试样本计算平均误差来近似，这些样本被称为测试数据集。这里训练集和测试集之间的关键区别在于测试样本是 *未见过的 (unseen)*，因为训练过程没有使用这些测试样本。在经典的统计学习设置中，训练样本和测试样本都从与测试分布 $\mathcal{D}$ 相同的分布中抽取，但测试样本对于学习过程来说仍然是未见过的，而训练样本是已见过的。[^2]

由于训练集和测试集之间的这种关键区别，即使它们都从相同的分布 $\mathcal{D}$ 中抽取，测试误差也不一定总是接近训练误差。[^3] 因此，成功最小化训练误差可能并不总是导致测试误差很小。如果模型在训练集上准确预测数据，但在其他测试样本上泛化能力不好，通常说模型 **过拟合 (overfits)** 数据，即训练误差小而测试误差大。如果训练误差相对较大[^4] (在这种情况下，测试误差通常也相对较大)，则说模型 **欠拟合 (underfits)** 数据。

本章研究学习过程如何影响测试误差，特别是模型参数化的选择。将测试误差分解为“偏差”和“方差”项，并研究模型参数化的选择及其权衡如何影响它们。利用偏差-方差权衡，将讨论何时发生过拟合和欠拟合以及如何避免。还将讨论 \ref{sec:8.2} 节中的双下降现象和 \ref{sec:8.3} 节中的一些经典理论结果。

## 8.1 偏差-方差均衡

lorem

### 8.1.1 (对于回归问题的) 数学分解

lorem

## 8.2 双下降现象

lorem

## 8.3 样本复杂度边界 (选读)

lorem

### 8.3.1 预备知识

lorem

### 8.3.2 有限 𝓗 的情况



### 8.3.3 无限 𝓗 的情况

[^1]: 在理论和统计文献中，通常将训练集 $\{(x^{(i)}, y^{(i)})\}_{i=1}^n$ 上的均匀分布称为经验分布，记为 $\hat{\mathcal{D}}$, 将总体分布称为 $\mathcal{D}$. 因此 (这是一部分原因)，训练损失也称为经验损失/风险/误差，测试损失也称为总体损失/风险/误差。

[^2]: 近年来，研究人员越来越关注“域偏移”的情况，即训练分布和测试分布不同。

[^3]: 训练误差和测试误差之间的差异通常称为泛化差距。泛化误差在一些文献中指测试误差，在其他一些文献中指泛化差距。

[^4]: 例如，大于回归问题中数据的内在噪声水平。
